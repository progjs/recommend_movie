{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영화 페이지 댓글로 유사도 분석\n",
    "* 네이버 영화에서 <다만 악에서 구하소서> 댓글을 scrapping\n",
    "* 댓글에서 단어만 추출\n",
    "* 유사도 측정\n",
    "* 특정 단어의 유사도 측정\n",
    "* https://movie.naver.com/movie/bi/mi/point.nhn?code=189069#tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 클리닝 함수 (file에 특수문자가 있을 경우 )\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    cleaned_text = re.sub('[a-zA-Z]', '', text)\n",
    "    cleaned_text = re.sub('[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]','', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이모티콘 제거\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "#분석에 어긋나는 불용어구 제외 (특수문자, 의성어)\n",
    "han = re.compile(r'[ㄱ-ㅎㅏ-ㅣ!?~,\".\\n\\r#\\ufeff\\u200d]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['박정민은 진심 올해의 히든카드였다 황정민이정재 사이에서 존재감 제대로 각인됨 20121201',\n",
       " '왜 내가 다 아픈기분이지 ㅋㅋㅋ 타격감이 그대로 느껴짐 ㅋㅋ 박민수',\n",
       " '박정민쵝오입니다믿고보는 기대가되는 배우 고승혁',\n",
       " '복도에서 마주친 그순간이 제일 재밌었음',\n",
       " '박정민 대박ㅋㅋㅋ 재밌고 시간 가는줄 모르고 보게 됨 누룽지탕',\n",
       " '반도따위랑 비교하지마라그냥올해본거중에 원탑 승현',\n",
       " '개봉하자마자 보고 왔는데 재밌습니다 적어도 최근 개봉한 영화들중에선 이게 제일 괜찮아요 아키라',\n",
       " '반도강철비다만악에서 구하소서 장원준1',\n",
       " '황정민 이정재 박정민을 데리고 왜 이런 개밥바라기 같은 영화를 만든거죠 말해봐요 왜그랬어요',\n",
       " '최근 나온 한국 영화들 중 최고입니다 우드0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_url = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=189069&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=3'\n",
    "res = requests.get(main_url)\n",
    "html = res.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "ptag_list = []\n",
    "for p_tag in soup.select(\".score_result .score_reple\"):\n",
    "    result = p_tag.text\n",
    "    result = result.replace('\\t','')\n",
    "    result = result.replace('\\r','')\n",
    "    result = result.replace('\\n','')\n",
    "    result = clean_text(result.replace('관람객', '').split('2020.')[0]).strip()\n",
    "    ptag_list.append(result)\n",
    "\n",
    "ptag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['박정민은 진심 올해의 히든카드였다 황정민이정재 사이에서 존재감 제대로 각인됨 20121201',\n",
       " '왜 내가 다 아픈기분이지  타격감이 그대로 느껴짐  박민수',\n",
       " '박정민쵝오입니다믿고보는 기대가되는 배우 고승혁',\n",
       " '복도에서 마주친 그순간이 제일 재밌었음',\n",
       " '박정민 대박 재밌고 시간 가는줄 모르고 보게 됨 누룽지탕',\n",
       " '반도따위랑 비교하지마라그냥올해본거중에 원탑 승현',\n",
       " '개봉하자마자 보고 왔는데 재밌습니다 적어도 최근 개봉한 영화들중에선 이게 제일 괜찮아요 아키라',\n",
       " '반도강철비다만악에서 구하소서 장원준1',\n",
       " '황정민 이정재 박정민을 데리고 왜 이런 개밥바라기 같은 영화를 만든거죠 말해봐요 왜그랬어요',\n",
       " '최근 나온 한국 영화들 중 최고입니다 우드0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_result = []\n",
    "\n",
    "for i in ptag_list:\n",
    "    tokens = re.sub(emoji_pattern,\"\",i)\n",
    "    tokens = re.sub(han,\"\",tokens)\n",
    "    comment_result.append(tokens)\n",
    "\n",
    "comment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\python37\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in c:\\python37\\lib\\site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\python37\\lib\\site-packages (from konlpy) (1.0.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in c:\\python37\\lib\\site-packages (from konlpy) (3.9.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\python37\\lib\\site-packages (from konlpy) (4.5.2)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\python37\\lib\\site-packages (from konlpy) (1.19.1)\n",
      "Requirement already satisfied: colorama in c:\\python37\\lib\\site-packages (from konlpy) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in c:\\python37\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (3.7.4.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python37\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\python37\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in c:\\python37\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (2.24.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python37\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\python37\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\python37\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\python37\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python37\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in c:\\python37\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: konlpy\n",
      "Version: 0.5.2\n",
      "Summary: Python package for Korean natural language processing.\n",
      "Home-page: http://konlpy.org\n",
      "Author: Team KoNLPy\n",
      "Author-email: konlpy@googlegroups.com\n",
      "License: GPL v3\n",
      "Location: c:\\python37\\lib\\site-packages\n",
      "Requires: JPype1, colorama, numpy, lxml, beautifulsoup4, tweepy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show konlpy\n",
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'konlpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4ef8428a0f6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKkma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_noun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment_txt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtwitter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTwitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnoun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'konlpy'"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "\n",
    "def get_noun(comment_txt):\n",
    "    twitter = Twitter()\n",
    "    noun = []\n",
    "    \n",
    "    if len(comment_txt)>0:\n",
    "        tw = twitter.pos(comment_txt)\n",
    "        for i,j in tw:\n",
    "            if j == 'Noun':\n",
    "                noun.append(i)\n",
    "    return noun\n",
    "\n",
    "kkma = Kkma()\n",
    "# kkma.nouns('연기는 손색이 없으나 스토리가 조금 빈약하지 않나 생각합니다 뽈티')\n",
    "noun_list = []\n",
    "for x in comment_result:\n",
    "    noun_list += kkma.nouns(x)\n",
    "\n",
    "noun_list = [a for a in noun_list if len(a) > 1]    \n",
    "noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: WordCloud in c:\\python37\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: pillow in c:\\python37\\lib\\site-packages (from WordCloud) (7.2.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\python37\\lib\\site-packages (from WordCloud) (1.19.1)\n",
      "Requirement already satisfied: matplotlib in c:\\python37\\lib\\site-packages (from WordCloud) (3.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python37\\lib\\site-packages (from matplotlib->WordCloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python37\\lib\\site-packages (from matplotlib->WordCloud) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\python37\\lib\\site-packages (from matplotlib->WordCloud) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\python37\\lib\\site-packages (from matplotlib->WordCloud) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\python37\\lib\\site-packages (from cycler>=0.10->matplotlib->WordCloud) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: wordcloud\n",
      "Version: 1.7.0\n",
      "Summary: A little word cloud generator\n",
      "Home-page: https://github.com/amueller/word_cloud\n",
      "Author: Andreas Mueller\n",
      "Author-email: t3kcit+wordcloud@gmail.com\n",
      "License: MIT\n",
      "Location: c:\\python37\\lib\\site-packages\n",
      "Requires: numpy, matplotlib, pillow\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'WordCloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-4dbf8e8f12e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mWordCloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwordcloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# import pytagcloud, pygame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'WordCloud'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from WordCloud import wordcloud\n",
    "# import pytagcloud, pygame\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "counts = Counter(noun_list)\n",
    "tags = counts.most_common(30)\n",
    "\n",
    "#bar chart\n",
    "test = pd.DataFrame({'word':[],\n",
    "                    'count':[]})\n",
    "for i in range(len(tags)):\n",
    "    word = tags[i][0]\n",
    "    count = tags[i][1]\n",
    "    \n",
    "    insert_data = pd.DataFrame({'word':[word],\n",
    "                                'count':[count]})\n",
    "    test = test.append(insert_data)\n",
    "\n",
    "test.index = range(len(test))\n",
    "\n",
    "index = np.arange(len(test))\n",
    "plt.bar(index,test['count'].tolist() )\n",
    "plt.xlabel('word', fontsize=5)\n",
    "plt.ylabel('count', fontsize=5)\n",
    "plt.xticks(index, test['word'].tolist(), fontsize=5, rotation=30)\n",
    "plt.title('단어 빈도수 시각화')\n",
    "plt.show()\n",
    "\n",
    "#wordcloud\n",
    "# taglist = pytagcloud.make_tags(tags, maxsize=50)\n",
    "# pytagcloud.create_tag_image(taglist, 'wordcloud.jpg', size=(600, 600), fontname='Korean', rectangular=False)\n",
    "\n",
    "#wordcloud\n",
    "wc = WordCloud(font_path='C:\\\\Windows\\\\Fonts\\\\NanumGothic.ttf',background_color='white', width=800, height=600)\n",
    "\n",
    "print(dict(tags))\n",
    "cloud = wc.generate_from_frequencies(dict(tags))\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.axis('off')\n",
    "plt.imshow(cloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e8129f1ccd7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomment_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkkma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "vec = []\n",
    "for x in comment_result:\n",
    "    tmp = [n for n in kkma.nouns(x) if len(n)>1]\n",
    "    vec.append(tmp)\n",
    "\n",
    "model = Word2Vec(vec, min_count=3,window=3,iter=20, size=100, sg=1) #skip-gram\n",
    "model.most_similar('연기')\n",
    "# model.most_similar('스토리')\n",
    "# model.most_similar('액션')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
