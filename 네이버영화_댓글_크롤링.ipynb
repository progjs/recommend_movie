{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영화 페이지 댓글로 유사도 분석\n",
    "* 네이버 영화에서 <다만 악에서 구하소서> 댓글을 scrapping\n",
    "* 댓글에서 단어만 추출\n",
    "* 유사도 측정\n",
    "* 특정 단어의 유사도 측정\n",
    "* https://movie.naver.com/movie/bi/mi/point.nhn?code=189069#tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 클리닝 함수 (file에 특수문자가 있을 경우 )\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    cleaned_text = re.sub('[a-zA-Z]', '', text)\n",
    "    cleaned_text = re.sub('[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]','', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이모티콘 제거\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "#분석에 어긋나는 불용어구 제외 (특수문자, 의성어)\n",
    "han = re.compile(r'[ㄱ-ㅎㅏ-ㅣ!?~,\".\\n\\r#\\ufeff\\u200d]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이정재 황정민 둘다 좋아하는 배우지만 박정민 때문에 놀란 1인 연기 스펙트럼 미쳤다 진짜 고릴라',\n",
       " '복도에서 마주친 그순간이 제일 재밌었음',\n",
       " '반도따위랑 비교하지마라그냥올해본거중에 원탑 승현',\n",
       " '박정민 대박ㅋㅋㅋ 재밌고 시간 가는줄 모르고 보게 됨 누룽지탕',\n",
       " '반도강철비다만악에서 구하소서 장원준1',\n",
       " '왜 내가 다 아픈기분이지 ㅋㅋㅋ 타격감이 그대로 느껴짐 ㅋㅋ 박민수',\n",
       " '개봉하자마자 보고 왔는데 재밌습니다 적어도 최근 개봉한 영화들중에선 이게 제일 괜찮아요 아키라',\n",
       " '감독이 그전에 어떤영화를 했나보게됨쩌는연기력을 저런 스토리와 맹락없는연출로ㅜㅜ 딱6점 조감독한테 연출시킨거같음',\n",
       " '최근 나온 한국 영화들 중 최고입니다 우드0',\n",
       " '간만에 영화다운 영화를 본 듯 황정민 이정재의 연기 케미도 짱이고 무엇보다 박정민 대박']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_url = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=189069&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=3'\n",
    "res = requests.get(main_url)\n",
    "html = res.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "ptag_list = []\n",
    "for p_tag in soup.select(\".score_result .score_reple\"):\n",
    "    result = p_tag.text\n",
    "    result = result.replace('\\t','')\n",
    "    result = result.replace('\\r','')\n",
    "    result = result.replace('\\n','')\n",
    "    result = clean_text(result.replace('관람객', '').split('2020.')[0]).strip()\n",
    "    ptag_list.append(result)\n",
    "\n",
    "ptag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이정재 황정민 둘다 좋아하는 배우지만 박정민 때문에 놀란 1인 연기 스펙트럼 미쳤다 진짜 고릴라',\n",
       " '복도에서 마주친 그순간이 제일 재밌었음',\n",
       " '반도따위랑 비교하지마라그냥올해본거중에 원탑 승현',\n",
       " '박정민 대박 재밌고 시간 가는줄 모르고 보게 됨 누룽지탕',\n",
       " '반도강철비다만악에서 구하소서 장원준1',\n",
       " '왜 내가 다 아픈기분이지  타격감이 그대로 느껴짐  박민수',\n",
       " '개봉하자마자 보고 왔는데 재밌습니다 적어도 최근 개봉한 영화들중에선 이게 제일 괜찮아요 아키라',\n",
       " '감독이 그전에 어떤영화를 했나보게됨쩌는연기력을 저런 스토리와 맹락없는연출로 딱6점 조감독한테 연출시킨거같음',\n",
       " '최근 나온 한국 영화들 중 최고입니다 우드0',\n",
       " '간만에 영화다운 영화를 본 듯 황정민 이정재의 연기 케미도 짱이고 무엇보다 박정민 대박']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_result = []\n",
    "\n",
    "for i in ptag_list:\n",
    "    tokens = re.sub(emoji_pattern,\"\",i)\n",
    "    tokens = re.sub(han,\"\",tokens)\n",
    "    comment_result.append(tokens)\n",
    "\n",
    "comment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\python37\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\python37\\lib\\site-packages (from konlpy) (1.19.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\i\\appdata\\roaming\\python\\python37\\site-packages (from konlpy) (0.4.3)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in c:\\python37\\lib\\site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\python37\\lib\\site-packages (from konlpy) (1.0.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in c:\\python37\\lib\\site-packages (from konlpy) (3.9.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\python37\\lib\\site-packages (from konlpy) (4.5.2)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in c:\\python37\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (3.7.4.2)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in c:\\python37\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (2.24.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\i\\appdata\\roaming\\python\\python37\\site-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python37\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\python37\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\python37\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python37\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\python37\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in c:\\python37\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python37\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.2 is available.\n",
      "You should consider upgrading via the 'c:\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: konlpy\n",
      "Version: 0.5.2\n",
      "Summary: Python package for Korean natural language processing.\n",
      "Home-page: http://konlpy.org\n",
      "Author: Team KoNLPy\n",
      "Author-email: konlpy@googlegroups.com\n",
      "License: GPL v3\n",
      "Location: c:\\python37\\lib\\site-packages\n",
      "Requires: numpy, tweepy, JPype1, beautifulsoup4, colorama, lxml\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show konlpy\n",
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'konlpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-4ef8428a0f6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKkma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_noun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment_txt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtwitter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTwitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnoun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'konlpy'"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "\n",
    "def get_noun(comment_txt):\n",
    "    twitter = Twitter()\n",
    "    noun = []\n",
    "    \n",
    "    if len(comment_txt)>0:\n",
    "        tw = twitter.pos(comment_txt)\n",
    "        for i,j in tw:\n",
    "            if j == 'Noun':\n",
    "                noun.append(i)\n",
    "    return noun\n",
    "\n",
    "kkma = Kkma()\n",
    "# kkma.nouns('연기는 손색이 없으나 스토리가 조금 빈약하지 않나 생각합니다 뽈티')\n",
    "noun_list = []\n",
    "for x in comment_result:\n",
    "    noun_list += kkma.nouns(x)\n",
    "\n",
    "noun_list = [a for a in noun_list if len(a) > 1]    \n",
    "noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting WordCloud\n",
      "  Downloading wordcloud-1.7.0-cp37-cp37m-win_amd64.whl (157 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.0-cp37-cp37m-win_amd64.whl (8.8 MB)\n",
      "Collecting pillow\n",
      "  Downloading Pillow-7.2.0-cp37-cp37m-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\python37\\lib\\site-packages (from WordCloud) (1.19.0)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\python37\\lib\\site-packages (from matplotlib->WordCloud) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp37-none-win_amd64.whl (57 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\i\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.1->matplotlib->WordCloud) (1.15.0)\n",
      "Installing collected packages: pyparsing, pillow, cycler, kiwisolver, matplotlib, WordCloud\n",
      "Successfully installed WordCloud-1.7.0 cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.3.0 pillow-7.2.0 pyparsing-2.4.7\n"
     ]
    }
   ],
   "source": [
    "!pip install WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: wordcloud\n",
      "Version: 1.7.0\n",
      "Summary: A little word cloud generator\n",
      "Home-page: https://github.com/amueller/word_cloud\n",
      "Author: Andreas Mueller\n",
      "Author-email: t3kcit+wordcloud@gmail.com\n",
      "License: MIT\n",
      "Location: c:\\python37\\lib\\site-packages\n",
      "Requires: matplotlib, numpy, pillow\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-bad7f9c58ed1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# import pytagcloud, pygame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "# import pytagcloud, pygame\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "counts = Counter(noun_list)\n",
    "tags = counts.most_common(30)\n",
    "\n",
    "#bar chart\n",
    "test = pd.DataFrame({'word':[],\n",
    "                    'count':[]})\n",
    "for i in range(len(tags)):\n",
    "    word = tags[i][0]\n",
    "    count = tags[i][1]\n",
    "    \n",
    "    insert_data = pd.DataFrame({'word':[word],\n",
    "                                'count':[count]})\n",
    "    test = test.append(insert_data)\n",
    "\n",
    "test.index = range(len(test))\n",
    "\n",
    "index = np.arange(len(test))\n",
    "plt.bar(index,test['count'].tolist() )\n",
    "plt.xlabel('word', fontsize=5)\n",
    "plt.ylabel('count', fontsize=5)\n",
    "plt.xticks(index, test['word'].tolist(), fontsize=5, rotation=30)\n",
    "plt.title('단어 빈도수 시각화')\n",
    "plt.show()\n",
    "\n",
    "#wordcloud\n",
    "# taglist = pytagcloud.make_tags(tags, maxsize=50)\n",
    "# pytagcloud.create_tag_image(taglist, 'wordcloud.jpg', size=(600, 600), fontname='Korean', rectangular=False)\n",
    "\n",
    "#wordcloud\n",
    "wc = WordCloud(font_path='C:\\\\Windows\\\\Fonts\\\\NanumGothic.ttf',background_color='white', width=800, height=600)\n",
    "\n",
    "print(dict(tags))\n",
    "cloud = wc.generate_from_frequencies(dict(tags))\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.axis('off')\n",
    "plt.imshow(cloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('정민', 0.04399838671088219),\n",
       " ('황정민', 0.013663563877344131),\n",
       " ('영화', 0.004850156605243683),\n",
       " ('박정민', -0.1256254017353058),\n",
       " ('이정재', -0.1721954047679901)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "vec = []\n",
    "for x in comment_result:\n",
    "    tmp = [n for n in kkma.nouns(x) if len(n)>1]\n",
    "    vec.append(tmp)\n",
    "\n",
    "model = Word2Vec(vec, min_count=3,window=3,iter=20, size=100, sg=1) #skip-gram\n",
    "model.most_similar('연기')\n",
    "# model.most_similar('스토리')\n",
    "# model.most_similar('액션')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp37-cp37m-win_amd64.whl (24.2 MB)\n",
      "Collecting scipy>=0.18.1\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-win_amd64.whl (31.2 MB)\n",
      "Collecting Cython==0.29.14\n",
      "  Downloading Cython-0.29.14-cp37-cp37m-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\python37\\lib\\site-packages (from gensim) (1.19.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\python37\\lib\\site-packages (from gensim) (1.15.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-2.1.0.tar.gz (116 kB)\n",
      "Requirement already satisfied: requests in c:\\python37\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Collecting boto\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.14.37-py2.py3-none-any.whl (129 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\python37\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python37\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\python37\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\python37\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.18.0,>=1.17.37\n",
      "  Downloading botocore-1.17.37-py2.py3-none-any.whl (6.5 MB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\python37\\lib\\site-packages (from botocore<1.18.0,>=1.17.37->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Using legacy setup.py install for smart-open, since package 'wheel' is not installed.\n",
      "Installing collected packages: scipy, Cython, boto, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
      "    Running setup.py install for smart-open: started\n",
      "    Running setup.py install for smart-open: finished with status 'done'\n",
      "Successfully installed Cython-0.29.14 boto-2.49.0 boto3-1.14.37 botocore-1.17.37 docutils-0.15.2 gensim-3.8.3 jmespath-0.10.0 s3transfer-0.3.3 scipy-1.5.2 smart-open-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
